{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec91d2ba-7ca4-4bd4-a6f5-c78a5b321179",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openicl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9acf526-7e21-4f95-9a94-fb3b00973e8d",
   "metadata": {},
   "source": [
    "# Self-adaptive In-context Learning\n",
    "---\n",
    "code for paper [Self-adaptive In-context Learning](https://arxiv.org/abs/2212.10375)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2e9c3a-c8eb-4a03-827f-253ed84b0c7e",
   "metadata": {},
   "source": [
    "## Templates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73a948c3-aa16-4b1e-9bc3-c6a6c0fdb7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openicl import PromptTemplate\n",
    "\n",
    "# SST-2\n",
    "sst2_tp_dict = {\n",
    "    0 : '</E>Positive Movie Review: \\\"<X>\\\"', \n",
    "    1 : '</E>Negative Movie Review: \\\"<X>\\\"',\n",
    "}\n",
    "sst2_template = PromptTemplate(sst2_tp_dict, column_token_map={'text' : '<X>'}, ice_token='</E>')\n",
    "\n",
    "# SST-5\n",
    "sst5_tp_dict = {\n",
    "    \n",
    "}\n",
    "\n",
    "# SNLI & MNLI\n",
    "xnli_tp_dict = {\n",
    "    0 : '</E><X1>? Yes, <X2>',\n",
    "    1 : '</E><X1>? Maybe, <X2>',\n",
    "    2 : '</E><X1>? No, <X2>'\n",
    "}\n",
    "xnli_template = PromptTemplate(xnli_tp_dict, column_token_map={'premise' : '<X1>', 'hypothesis' : '<X2>'}, ice_token='</E>')\n",
    "\n",
    "# QNLI \n",
    "\n",
    "# TREC\n",
    "\n",
    "# AgNews\n",
    "\n",
    "# Commonsense QA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af99167-f0a0-44ee-964d-701ec781265c",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f28ecda-13f8-430c-a0c9-c85e52c806cf",
   "metadata": {},
   "source": [
    "### MDL (method in this paper)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab9b389-b2f1-488e-b434-c3a48667b91c",
   "metadata": {},
   "source": [
    "#### 3. SNLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3bc424-fe92-4b2a-9d5f-ac942ebc675f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openicl import DatasetReader, MDLRetriever, PPLInferencer, AccEvaluator\n",
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset('snli')\n",
    "\n",
    "# If you only want to test part of the test set, you can use the following code\n",
    "# dataset['test'] = dataset['test'].select(list(range(100)))\n",
    "\n",
    "data = DatasetReader(dataset, input_columns=['premise', 'hypothesis'], output_column='label')\n",
    "\n",
    "# Maybe we use a different seed, but the results are very closed.\n",
    "# If you don't have enough memory, you can leave `batch_size` unset\n",
    "retriever = MDLRetriever(data, ice_num=8, candidate_num=30, select_time=10, seed=1, batch_size=12, ice_template=xnli_template)\n",
    "\n",
    "inferencer = PPLInferencer(model_name='gpt2-xl', batch_size=8)\n",
    "\n",
    "predictions = inferencer.inference(retriever, ice_template=xnli_template, output_json_filename='mdl_snli')\n",
    "\n",
    "scores = AccEvaluator().score(predictions=predictions, references=data.references)\n",
    "print(scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
